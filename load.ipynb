{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, WebBaseLoader, YoutubeLoader, DirectoryLoader, TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from google.colab import userdata\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
    "os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
    "\n",
    "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "embed_model = \"text-embedding-3-small\"\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text, \n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter =RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=tiktoken_len,\n",
    "    seperators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    # Call the OpenAI API to get the embedding for the text\n",
    "    response = openai_client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def cosine_similarity_between_words(sentence1, sentence2):\n",
    "    # Get embeddings for both words\n",
    "    embedding1 = np.array(get_embedding(sentence1))\n",
    "    embedding2 = np.array(get_embedding(sentence2))\n",
    "\n",
    "    # Reshape embeddings for cosine_similarity function\n",
    "    embedding1 = embedding1.reshape(1,-1)\n",
    "    embeddin21 = embedding2.reshape(1,-1)\n",
    "\n",
    "    print(\"Embedding for Sentence 1:\", embedding1)\n",
    "    print(\"\\nEmbedding for Sentence 2:\", embedding2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(embedding1, embedding2)\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Example\n",
    "sentence1 = \"I like walking to the park\"\n",
    "sentence2 = \"I like walking to the office\"\n",
    "\n",
    "similarity = cosine_similarity_between_words(sentence1, sentence2)\n",
    "print(f\"\\n\\nCosine similarity between '{sentence1}' and '{sentence2}': '{similarity:4f}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
